{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: A single data scientist participating in an ML competition\n",
    "\n",
    "MLflow setup:\n",
    "* Tracking server: no\n",
    "* Backend store: local filesystem\n",
    "* Artifacts store: local filesystem\n",
    "\n",
    "The experiments can be explored locally by launching the MLflow UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will assume that we want to save our files and artifacts on the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'file:///home/filipe/Documents/education/mlops-zoomcamp/02-experiment-tracking/running-mlflow-examples/mlruns'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create the mlruns folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/filipe/Documents/education/mlops-zoomcamp/02-experiment-tracking/running-mlflow-examples/mlruns/0', creation_time=1685106797118, experiment_id='0', last_update_time=1685106797118, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the created folder, you can see two sub-folders: .trash and 0, which is the experiment_id. This latter contains information about the experiment saved in an YAML file meta.yaml. \n",
    "\n",
    "### Creating an experiment and logging a new run\n",
    "This code will create a new experiment, so inside the mlruns folders a new folder named after the experiment ID will be created*. Inside it, there will be a new folder for anything you asked mlflow to log, in this case: params, metrics, models (which are save inside the artifacts folder). The tags are also saved. Everything will be save on individual files inside these folders.\n",
    "\n",
    "*In the video, this folder has ID 1, following the order, but here my created folder has what seems to be a random ID. I don't know why this happened, probably because of some different configuration - remember the video was recorded with an older version of MLflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/26 10:20:45 INFO mlflow.tracking.fluent: Experiment with name 'my-experiment-1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///home/filipe/Documents/education/mlops-zoomcamp/02-experiment-tracking/running-mlflow-examples/mlruns/310781406204023939/9eb2a0e59f7b45dfb613fff70f61f796/artifacts'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_experiment(\"my-experiment-1\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we run this command again, we are going to see a new experiment being shown in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/filipe/Documents/education/mlops-zoomcamp/02-experiment-tracking/running-mlflow-examples/mlruns/310781406204023939', creation_time=1685107245818, experiment_id='310781406204023939', last_update_time=1685107245818, lifecycle_stage='active', name='my-experiment-1', tags={}>,\n",
       " <Experiment: artifact_location='file:///home/filipe/Documents/education/mlops-zoomcamp/02-experiment-tracking/running-mlflow-examples/mlruns/0', creation_time=1685106797118, experiment_id='0', last_update_time=1685106797118, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to run the MLflow UI, we have to, on the terminal, move to the directory where the mlruns folder of interested is located (in this case, it is in the same folder of this notebook). If you run it on the wrong directory, it will create a new mlruns folder there, or use one that already exists there. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "try:\n",
    "    client.search_registered_models()\n",
    "except MlflowException:\n",
    "    print(\"It's not possible to access the model registry :(\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are going to delete the mlruns folder that was created for this scenario in order to explore scenario 2."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0848c9d6c7d415ad6c477ff7ff8e98694d1a4aa96d0deee89244642e6b630036"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exp-tracking-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
